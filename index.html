<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enhanced LLM Chat Interface</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f0f2f5;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
        }
        #chat-container {
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            height: 500px;
            overflow-y: scroll;
            padding: 20px;
            margin-bottom: 20px;
        }
        #input-container {
            display: flex;
            margin-bottom: 20px;
        }
        #user-input {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 20px;
            font-size: 16px;
        }
        #send-btn {
            background-color: #2c3e50;
            color: white;
            border: none;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            margin-left: 10px;
            cursor: pointer;
            font-size: 18px;
        }
        .message {
            margin-bottom: 15px;
            display: flex;
            align-items: flex-start;
        }
        .message-content {
            max-width: 80%;
            padding: 10px 15px;
            border-radius: 18px;
            font-size: 16px;
        }
        .user-message {
            justify-content: flex-end;
        }
        .user-message .message-content {
            background-color: #0084ff;
            color: white;
            margin-left: auto;
        }
        .ai-message .message-content {
            background-color: #f0f0f0;
        }
        .ai-icon {
            width: 30px;
            height: 30px;
            margin-right: 10px;
            border-radius: 50%;
            background-color: #2c3e50;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
        }
        #model-select {
            width: 100%;
            padding: 10px;
            margin-bottom: 20px;
            border-radius: 5px;
            border: 1px solid #ddd;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <h1>Enhanced LLM Chat Interface</h1>
    <select id="model-select">
        <option value="claude">Claude</option>
        <option value="openai">OpenAI</option>
        <option value="gemini">Gemini</option>
    </select>
    <div id="chat-container"></div>
    <div id="input-container">
        <input type="text" id="user-input" placeholder="Type your message here...">
        <button id="send-btn">âž¤</button>
    </div>

    <script>
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const modelSelect = document.getElementById('model-select');

        sendBtn.addEventListener('click', sendMessage);
        userInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });

        function sendMessage() {
            const message = userInput.value.trim();
            if (message) {
                addMessageToChat('user', message);
                generateAIResponse(message);
                userInput.value = '';
            }
        }

        function addMessageToChat(sender, message) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('message', `${sender}-message`);
            
            if (sender === 'ai') {
                const iconElement = document.createElement('div');
                iconElement.classList.add('ai-icon');
                iconElement.textContent = 'AI';
                messageElement.appendChild(iconElement);
            }

            const contentElement = document.createElement('div');
            contentElement.classList.add('message-content');
            contentElement.textContent = message;
            messageElement.appendChild(contentElement);

            chatContainer.appendChild(messageElement);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        async function generateAIResponse(userMessage) {
            const model = modelSelect.value;
            addMessageToChat('ai', 'Thinking...');
            
            try {
                // In a real implementation, you would make an API call here
                // For now, we'll simulate a response
                const response = await simulateApiCall(model, userMessage);
                chatContainer.removeChild(chatContainer.lastChild); // Remove "Thinking..." message
                addMessageToChat('ai', response);
            } catch (error) {
                chatContainer.removeChild(chatContainer.lastChild); // Remove "Thinking..." message
                addMessageToChat('ai', 'Error: Unable to generate response.');
            }
        }

        async function simulateApiCall(model, prompt) {
            // Simulate API delay
            await new Promise(resolve => setTimeout(resolve, 1000));

            // Simulate different responses based on the model
            switch (model) {
                case 'claude':
                    return `Claude: Hello! I'm happy to help with "${prompt}". What would you like to know?`;
                case 'openai':
                    return `OpenAI: This is a simulated response to "${prompt}". In a real implementation, you would call the OpenAI API here.`;
                case 'gemini':
                    return `Gemini: This is a simulated response to "${prompt}". In a real implementation, you would call the Gemini API here.`;
                default:
                    return `Unknown model: Unable to process "${prompt}".`;
            }
        }
    </script>
</body>
</html>
